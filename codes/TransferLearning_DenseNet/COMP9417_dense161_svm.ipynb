{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rice leaf classification\n",
    "\n",
    "\n",
    "## Introduction\n",
    "This code uses a CNN model to extract features then dose classification by SVM. The result will be compared with other methods to choose the best one. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxFQ7RBU0J75"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.svm import SVC\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpPBlE_O0fTj",
    "outputId": "16fb6507-bbbe-4b56-8782-efe471f2c2fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SexfdrtN0lX8"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "  def __init__(self, csv_file, transform=None):\n",
    "    self.data_frame = pd.read_csv(csv_file)\n",
    "    self.transform = transform\n",
    "    self.classes = sorted(self.data_frame['class'].unique())\n",
    "    self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_frame)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "\n",
    "    img_path = self.data_frame.loc[idx, \"path\"]\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "    label = self.data_frame.loc[idx, \"class\"]\n",
    "    label_idx = self.class_to_idx[label]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Dkc6OkGF06To"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(), # convert a PIL Image or numpy.ndarray to a PyTorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source description\n",
    "This dataset is a collection of multiple data sets found online. The size of this dataset is 7 GB due to the high resolution of images. The number of images in the dataset is 3355, including 3 types of rice diseases and the healthy leaf.\n",
    "\n",
    "### Data source link\n",
    "Download the dataset through the link below, unzip and save the dataset in the current directory https://www.kaggle.com/datasets/shayanriyaz/riceleafs <br>\n",
    "Revise the below path so images can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMzN_k6P0_Q5",
    "outputId": "ec2b9d63-b369-4ae3-9772-1ad4f393362f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brown spot: 105\n",
      "Number of healthy: 287\n",
      "Number of hispa:  113\n",
      "Number of leaf blast: 156\n",
      "Total number: 661\n"
     ]
    }
   ],
   "source": [
    "# just for test\n",
    "brown_spot = glob(\"../content/drive/MyDrive/riceleaf/RiceLeafs/validation/BrownSpot/*\")\n",
    "healthy = glob(\"../content/drive/MyDrive/riceleaf/RiceLeafs/validation/Healthy/*\")\n",
    "hispa = glob(\"../content/drive/MyDrive/riceleaf/RiceLeafs/validation/Hispa/*\")\n",
    "leaf_blast = glob(\"../content/drive/MyDrive/riceleaf/RiceLeafs/validation/LeafBlast/*\")\n",
    "\n",
    "print(\"Number of brown spot:\",len(brown_spot))\n",
    "print(\"Number of healthy:\",len(healthy))\n",
    "print(\"Number of hispa: \",len(hispa))\n",
    "print(\"Number of leaf blast:\",len(leaf_blast))\n",
    "print('Total number:',len(brown_spot)+len(healthy)+len(hispa)+len(leaf_blast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lMbtDf3z1yp3"
   },
   "outputs": [],
   "source": [
    "label_map = {0:\"brown_spot\",\n",
    "             1:\"healthy\",\n",
    "             2:\"hispa\",\n",
    "             3:\"leaf_blast\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "Resize<br>\n",
    "Normalization<br>\n",
    "Standarlization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "chtugr5r12cu"
   },
   "outputs": [],
   "source": [
    "# Reference https://www.kaggle.com/code/mehmetlaudatekman/rice-leaf-pytorch-transfer-learning\n",
    "class LeafDataset(Dataset):\n",
    "    \n",
    "    def __init__(self,paths):\n",
    "        \n",
    "        self.x = []\n",
    "        self.y = []                         # This converts pil image to torch tensor.\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                             # We have to normalize data to use in torchvision models.\n",
    "                                             transforms.Normalize(mean=[0.485, 0.456, 0.406],                                     std=[0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "        \n",
    "        start = time.time()\n",
    "        for label,class_paths in enumerate(paths):\n",
    "            for sample_path in class_paths:\n",
    "                img = Image.open(sample_path).resize((224,224))\n",
    "                self.x.append(self.transform(img))\n",
    "                self.y.append(label)\n",
    "        end = time.time()\n",
    "        process_time = round(end-start,2)\n",
    "        print(\"Dataset has loaded, that took {} seconds\".format(process_time))\n",
    "        \n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index],self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xvpZr7I4HPB",
    "outputId": "f61f535d-f776-42ab-a95e-b888e87bfbd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has loaded, that took 262.67 seconds\n"
     ]
    }
   ],
   "source": [
    "dataset = LeafDataset((brown_spot,healthy,hispa,leaf_blast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ux_iPNck6XPf",
    "outputId": "82b8e8f3-79f6-4303-d3eb-8fb06dfc226e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "# Splitting indices into train and test sets.\n",
    "train,test = train_test_split(list(range(len(dataset))))\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9I6L-R9Jl7IZ",
    "outputId": "ab31a928-f7a6-449f-85a7-31dc07b1cafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n",
      "166\n"
     ]
    }
   ],
   "source": [
    "train_sampler = SubsetRandomSampler(train)\n",
    "test_sampler = SubsetRandomSampler(test)\n",
    "print(len(train_sampler))\n",
    "print(len(test_sampler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8q-wLp9J7PBx"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_loader = DataLoader(dataset,batch_size=BATCH_SIZE,sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset,batch_size=BATCH_SIZE,sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load a pre-trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qTcuLY_d7wNH",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5b321f06-4931-4586-e24a-e9942f33244c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet161-8d451a50.pth\" to /root/.cache/torch/hub/checkpoints/densenet161-8d451a50.pth\n",
      "100%|██████████| 110M/110M [00:00<00:00, 129MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model \n",
    "d161 = torchvision.models.densenet161(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "id": "W87kKZ4Vn96J",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Remove the last layer of the model\n",
    "\n",
    "feature_extractor = nn.Sequential(*list(d161.children())[:-1])\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features by CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "o7DuUbXZDOEf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a6610492-4e6f-41aa-dc5c-4f92873462e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-149-4cf14ea2438e>:20: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  y_train = np.asarray(y_train, dtype=np.float32)\n",
      "<ipython-input-149-4cf14ea2438e>:20: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "  y_train = np.asarray(y_train, dtype=np.float32)\n",
      "<ipython-input-149-4cf14ea2438e>:34: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  y_test = np.asarray(y_test, dtype=np.float32)\n",
      "<ipython-input-149-4cf14ea2438e>:34: DeprecationWarning: setting an array element with a sequence. This was supported in some cases where the elements are arrays with a single element. For example `np.array([1, np.array([2])], dtype=int)`. In the future this will raise the same ValueError as `np.array([1, [2]], dtype=int)`.\n",
      "  y_test = np.asarray(y_test, dtype=np.float32)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset and extract features\n",
    "# Reference: https://discuss.pytorch.org/t/how-to-extract-features-of-an-image-from-a-trained-model/119/105?page=6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(d161.parameters(), lr=0.0001)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for input, label in train_loader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feature_vector = feature_extractor(input)\n",
    "    \n",
    "    X_train.append(feature_vector.numpy().flatten())\n",
    "    \n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.asarray(X_train, dtype=np.float32)\n",
    "y_train = np.asarray(y_train, dtype=np.float32) \n",
    "\n",
    "# same operation for test set\n",
    "for input, label in test_loader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feature_vector = feature_extractor(input)\n",
    "    \n",
    "    X_test.append(feature_vector.numpy().flatten())\n",
    "    \n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.asarray(X_test, dtype=np.float32)\n",
    "y_test = np.asarray(y_test, dtype=np.float32)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify by SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Me23qpXO0pyG",
    "outputId": "72e7cf6f-6230-4bd0-88c0-d1d2044af68e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5542, Precision: 0.5084, Recall: 0.5542, F1 score: 0.4774\n"
     ]
    }
   ],
   "source": [
    "clf2 = SVC(kernel='linear', C=1, decision_function_shape='ovr')\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the SVM classifier on the test set\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "val_acc = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings:\n",
    "- Based on the above attempt, the CNN + SVM did not get as good effect as other CNN models."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
